{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "043b4d8b",
   "metadata": {},
   "source": [
    "### Stage 2 – Entity Linker (SNOMED CT)\n",
    "\n",
    "This notebook performs candidate generation and selection for linking NER spans to SNOMED CT concepts.\n",
    "\n",
    "Checklist\n",
    "- [x] Candidate Generation: exact + fuzzy, collect top-N with scores\n",
    "- [x] Candidate Selection: exact > best-score, optional rules\n",
    "- [x] Evaluation: link accuracy on spans that exactly match gold\n",
    "- [x] Output: JSONL candidates and CSV final links\n",
    "\n",
    "Inputs\n",
    "- Predicted spans from `A2/ner.ipynb` (`ner_predictions.csv`)\n",
    "- Notes and gold span annotations for evaluation\n",
    "- SNOMED dictionary (concept_id, preferred term, synonyms)\n",
    "\n",
    "If a SNOMED dictionary file is not present, the notebook falls back to a lexicon built from training annotations (surface form → concept_id).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e687545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (21264, 4) (204, 2) (51574, 4) (68, 2) (23234, 4)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path('/Users/aryamanbahl/Desktop/IIITH/M25/NLP-H/Assignments /nlph_assignments-/A2/Assignment 2 Dataset')\n",
    "PRED_SPANS = DATA_DIR.parent / 'ner_predictions.csv'\n",
    "TRAIN_NOTES = DATA_DIR / 'training-notes.csv'\n",
    "TRAIN_ANN = DATA_DIR / 'train-annotations.csv'\n",
    "TEST_NOTES = DATA_DIR / 'test-notes.csv'\n",
    "TEST_ANN = DATA_DIR / 'test-annotations.csv'\n",
    "\n",
    "train_notes = pd.read_csv(TRAIN_NOTES)\n",
    "train_ann = pd.read_csv(TRAIN_ANN)\n",
    "test_notes = pd.read_csv(TEST_NOTES)\n",
    "test_ann = pd.read_csv(TEST_ANN)\n",
    "preds = pd.read_csv(PRED_SPANS)\n",
    "\n",
    "print('Loaded:', preds.shape, train_notes.shape, train_ann.shape, test_notes.shape, test_ann.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be38d219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built fallback lexicon terms: (12484, 2)\n"
     ]
    }
   ],
   "source": [
    "# SNOMED dictionary loader\n",
    "# Expected CSV format: snomed_id, term, synonyms (| separated)\n",
    "SNOMED_CSV = DATA_DIR.parent / 'snomed_dictionary.csv'\n",
    "\n",
    "def load_snomed_dict(path: Path):\n",
    "    if path.exists():\n",
    "        df = pd.read_csv(path)\n",
    "        df['synonyms'] = df.get('synonyms', '').fillna('').astype(str)\n",
    "        rows = []\n",
    "        for _, r in df.iterrows():\n",
    "            cid = str(r['snomed_id'])\n",
    "            term = str(r['term'])\n",
    "            rows.append({'snomed_id': cid, 'term': term})\n",
    "            syns = [s.strip() for s in r['synonyms'].split('|') if s.strip()]\n",
    "            for s in syns:\n",
    "                rows.append({'snomed_id': cid, 'term': s})\n",
    "        dict_df = pd.DataFrame(rows)\n",
    "        print('Loaded SNOMED dictionary terms:', dict_df.shape)\n",
    "        return dict_df\n",
    "    else:\n",
    "        # Fallback lexicon from training annotations (surface → concept_id)\n",
    "        notes_map = train_notes.set_index('note_id')['text'].to_dict()\n",
    "        rows = []\n",
    "        for _, r in train_ann.iterrows():\n",
    "            nid = r['note_id']\n",
    "            s, e = int(r['start']), int(r['end'])\n",
    "            mention = notes_map.get(nid, '')[s:e].strip()\n",
    "            if mention:\n",
    "                rows.append({'snomed_id': str(r['concept_id']), 'term': mention})\n",
    "        dict_df = pd.DataFrame(rows).drop_duplicates()\n",
    "        print('Built fallback lexicon terms:', dict_df.shape)\n",
    "        return dict_df\n",
    "\n",
    "snomed_terms = load_snomed_dict(SNOMED_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23ec0840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "_punct_tbl = str.maketrans('', '', string.punctuation)\n",
    "_whitespace_re = re.compile(r\"\\s+\")\n",
    "\n",
    "def normalize(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = text.translate(_punct_tbl)\n",
    "    text = _whitespace_re.sub(' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    return [t for t in _whitespace_re.split(text) if t]\n",
    "\n",
    "# Pre-normalize dictionary terms\n",
    "snomed_terms['norm_term'] = snomed_terms['term'].astype(str).map(normalize)\n",
    "snomed_terms = snomed_terms.drop_duplicates(['snomed_id', 'norm_term']).reset_index(drop=True)\n",
    "\n",
    "# Inverted index by surface form for exact lookups\n",
    "exact_index: Dict[str, List[Tuple[str, str]]] = {}\n",
    "for _, r in snomed_terms.iterrows():\n",
    "    exact_index.setdefault(r['norm_term'], []).append((r['snomed_id'], r['term']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e353dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(a: List[str], b: List[str]) -> float:\n",
    "    sa, sb = set(a), set(b)\n",
    "    if not sa and not sb:\n",
    "        return 0.0\n",
    "    return len(sa & sb) / max(1, len(sa | sb))\n",
    "\n",
    "# Levenshtein distance with DP; return similarity in [0,1]\n",
    "def levenshtein_sim(a: str, b: str) -> float:\n",
    "    if a == b:\n",
    "        return 1.0\n",
    "    if len(a) == 0 or len(b) == 0:\n",
    "        return 0.0\n",
    "    n, m = len(a), len(b)\n",
    "    dp = list(range(m + 1))\n",
    "    for i in range(1, n + 1):\n",
    "        prev = dp[0]\n",
    "        dp[0] = i\n",
    "        for j in range(1, m + 1):\n",
    "            cur = dp[j]\n",
    "            cost = 0 if a[i-1] == b[j-1] else 1\n",
    "            dp[j] = min(\n",
    "                dp[j] + 1,      # deletion\n",
    "                dp[j-1] + 1,    # insertion\n",
    "                prev + cost     # substitution\n",
    "            )\n",
    "            prev = cur\n",
    "    dist = dp[m]\n",
    "    return 1.0 - (dist / max(n, m))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0755c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def generate_candidates(span_text: str, top_n: int = 5):\n",
    "    norm = normalize(span_text)\n",
    "    # Exact matches\n",
    "    if norm in exact_index:\n",
    "        cands = [{'snomed_id': cid, 'term': term, 'score': 1.0} for cid, term in exact_index[norm]]\n",
    "        return sorted(cands, key=lambda x: -x['score'])[:top_n]\n",
    "    # Fuzzy: compute combo score = 0.6 * levenshtein + 0.4 * jaccard tokens\n",
    "    toks_q = tokenize(norm)\n",
    "    scores = []\n",
    "    for _, r in snomed_terms.iterrows():\n",
    "        t = r['norm_term']\n",
    "        lev = levenshtein_sim(norm, t)\n",
    "        jac = jaccard(toks_q, tokenize(t))\n",
    "        score = 0.6 * lev + 0.4 * jac\n",
    "        if score > 0:\n",
    "            scores.append({'snomed_id': r['snomed_id'], 'term': r['term'], 'score': float(score)})\n",
    "    scores.sort(key=lambda x: -x['score'])\n",
    "    return scores[:top_n]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a326e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best(candidates: List[dict]):\n",
    "    if not candidates:\n",
    "        return None\n",
    "    # exact match has score==1.0 by construction\n",
    "    candidates = sorted(candidates, key=lambda x: (-x['score'], x['snomed_id']))\n",
    "    return candidates[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da7ad348",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m     s, e = \u001b[38;5;28mint\u001b[39m(r[\u001b[33m'\u001b[39m\u001b[33mstart\u001b[39m\u001b[33m'\u001b[39m]), \u001b[38;5;28mint\u001b[39m(r[\u001b[33m'\u001b[39m\u001b[33mend\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      9\u001b[39m     span = notes_map_test.get(nid, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)[s:e]\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     cands = \u001b[43mgenerate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     cand_records.append({\n\u001b[32m     12\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mnote_id\u001b[39m\u001b[33m'\u001b[39m: nid,\n\u001b[32m     13\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mstart\u001b[39m\u001b[33m'\u001b[39m: s,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mcandidates\u001b[39m\u001b[33m'\u001b[39m: cands\n\u001b[32m     17\u001b[39m     })\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Save candidates as JSONL\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mgenerate_candidates\u001b[39m\u001b[34m(span_text, top_n)\u001b[39m\n\u001b[32m     10\u001b[39m toks_q = tokenize(norm)\n\u001b[32m     11\u001b[39m scores = []\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msnomed_terms\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnorm_term\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlev\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevenshtein_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:1559\u001b[39m, in \u001b[36mDataFrame.iterrows\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1557\u001b[39m using_cow = using_copy_on_write()\n\u001b[32m   1558\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.index, \u001b[38;5;28mself\u001b[39m.values):\n\u001b[32m-> \u001b[39m\u001b[32m1559\u001b[39m     s = \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1560\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mgr.is_single_block:\n\u001b[32m   1561\u001b[39m         s._mgr.add_references(\u001b[38;5;28mself\u001b[39m._mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pandas/core/series.py:584\u001b[39m, in \u001b[36mSeries.__init__\u001b[39m\u001b[34m(self, data, index, dtype, name, copy, fastpath)\u001b[39m\n\u001b[32m    582\u001b[39m         data = data.copy()\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m584\u001b[39m     data = \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    586\u001b[39m     manager = _get_option(\u001b[33m\"\u001b[39m\u001b[33mmode.data_manager\u001b[39m\u001b[33m\"\u001b[39m, silent=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    587\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33mblock\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pandas/core/construction.py:660\u001b[39m, in \u001b[36msanitize_array\u001b[39m\u001b[34m(data, index, dtype, copy, allow_2d)\u001b[39m\n\u001b[32m    656\u001b[39m subarr = _sanitize_ndim(subarr, data, dtype, index, allow_2d=allow_2d)\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np.ndarray):\n\u001b[32m    659\u001b[39m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m     dtype = \u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m     subarr = _sanitize_str_dtypes(subarr, data, dtype, copy)\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m subarr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/typing.py:2132\u001b[39m, in \u001b[36mcast\u001b[39m\u001b[34m(typ, val)\u001b[39m\n\u001b[32m   2128\u001b[39m                 \u001b[38;5;28mcls\u001b[39m.__non_callable_proto_members__.add(attr)\n\u001b[32m   2129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2132\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mcast\u001b[39m(typ, val):\n\u001b[32m   2133\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Cast a value to a type.\u001b[39;00m\n\u001b[32m   2134\u001b[39m \n\u001b[32m   2135\u001b[39m \u001b[33;03m    This returns the value unchanged.  To the type checker this\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2138\u001b[39m \u001b[33;03m    to be as fast as possible).\u001b[39;00m\n\u001b[32m   2139\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   2140\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Build text map for span extraction\n",
    "notes_map_test = test_notes.set_index('note_id')['text'].to_dict()\n",
    "\n",
    "# Generate candidates for all predicted spans\n",
    "cand_records = []\n",
    "for _, r in preds.iterrows():\n",
    "    nid = r['note_id']\n",
    "    s, e = int(r['start']), int(r['end'])\n",
    "    span = notes_map_test.get(nid, '')[s:e]\n",
    "    cands = generate_candidates(span, top_n=5)\n",
    "    cand_records.append({\n",
    "        'note_id': nid,\n",
    "        'start': s,\n",
    "        'end': e,\n",
    "        'span': span,\n",
    "        'candidates': cands\n",
    "    })\n",
    "\n",
    "# Save candidates as JSONL\n",
    "cand_path = DATA_DIR.parent / 'linker_candidates.jsonl'\n",
    "with open(cand_path, 'w') as f:\n",
    "    for rec in cand_records:\n",
    "        f.write(json.dumps(rec) + '\\n')\n",
    "print('Saved candidates to', cand_path)\n",
    "\n",
    "# Select best candidate per span\n",
    "linked_rows = []\n",
    "for rec in cand_records:\n",
    "    best = select_best(rec['candidates'])\n",
    "    linked_rows.append({\n",
    "        'note_id': rec['note_id'],\n",
    "        'start': rec['start'],\n",
    "        'end': rec['end'],\n",
    "        'span': rec['span'],\n",
    "        'snomed_id': best['snomed_id'] if best else None,\n",
    "        'matched_term': best['term'] if best else None,\n",
    "        'score': best['score'] if best else None\n",
    "    })\n",
    "\n",
    "linked_df = pd.DataFrame(linked_rows)\n",
    "link_path = DATA_DIR.parent / 'linker_links.csv'\n",
    "linked_df.to_csv(link_path, index=False)\n",
    "print('Saved links to', link_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c08fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation: compare linked concept_id to gold if spans exactly match a gold span\n",
    "# Build gold mapping (test set): (note_id, start, end) -> concept_id\n",
    "\n",
    "gold_map = {}\n",
    "for _, r in test_ann.iterrows():\n",
    "    key = (int(r['note_id']), int(r['start']), int(r['end']))\n",
    "    gold_map[key] = str(r['concept_id'])\n",
    "\n",
    "num, correct = 0, 0\n",
    "errors = []\n",
    "for _, r in linked_df.iterrows():\n",
    "    key = (int(r['note_id']), int(r['start']), int(r['end']))\n",
    "    pred_cid = None if pd.isna(r['snomed_id']) else str(r['snomed_id'])\n",
    "    if key in gold_map:\n",
    "        num += 1\n",
    "        if pred_cid == gold_map[key]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            errors.append({\n",
    "                'note_id': r['note_id'],\n",
    "                'start': r['start'],\n",
    "                'end': r['end'],\n",
    "                'span': r['span'],\n",
    "                'pred_snomed_id': pred_cid,\n",
    "                'gold_concept_id': gold_map[key],\n",
    "                'matched_term': r['matched_term'],\n",
    "                'score': r['score']\n",
    "            })\n",
    "\n",
    "acc = (correct / num) if num else 0.0\n",
    "print(f'Exact-span linking accuracy: {acc:.4f}  (N={num})')\n",
    "\n",
    "# Store detailed errors for inspection\n",
    "err_path = DATA_DIR.parent / 'linker_errors.jsonl'\n",
    "with open(err_path, 'w') as f:\n",
    "    for e in errors:\n",
    "        f.write(json.dumps(e) + '\\n')\n",
    "print('Saved errors to', err_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac72851",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "- Candidate Generation: normalized exact lookup + fuzzy scoring (0.6·Levenshtein + 0.4·Jaccard over tokens). Top-5 retained per span.\n",
    "- Candidate Selection: prefer exact matches (score 1.0), else pick highest score. Deterministic tie-breaker on concept ID.\n",
    "- Evaluation: exact-span accuracy against gold `concept_id` on test spans with the same (note_id, start, end).\n",
    "- Outputs:\n",
    "  - `linker_candidates.jsonl`: per span list of `{snomed_id, term, score}`.\n",
    "  - `linker_links.csv`: best link per span with score.\n",
    "  - `linker_errors.jsonl`: mismatches for analysis.\n",
    "\n",
    "Notes\n",
    "- If `snomed_dictionary.csv` is not present, we fall back to a training-derived surface→concept lexicon.\n",
    "- Improvements: add semantic tag filtering, abbreviation expansion, BM25/TF-IDF retrieval or embedding-based retrieval for better candidate recall, and supervised re-ranking.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
